---
    title: "LLMs Are Thinking Tools, Not Reading Replacement"
    date: 2026-01-25T22:00:00+05:30  
    draft: false
    tags: ["LLMs", "Thinking Tools"]
    categories: ["Guide"]           # pick one or more
    description: "Why outsourcing reading to AI quietly erodes depth, retention, and original thought"
---

Large Language Models (LLMs) were designed to predict the next word. Somehow, we decided that this also qualified them to read on our behalf. Today, LLMs summarise books, compress long-form thinking, and explain complex ideas in seconds. For a culture obsessed with speed and efficiency, this feels like a step forward.

But reading was never meant to be efficient. Understanding emerges from slowness; from pausing, rereading, getting stuck, and forming incomplete thoughts. When we replace reading with summaries, we remove the very friction that turns information into knowledge. What remains is clarity without struggle, confidence without depth, and familiarity mistaken for insight. **Reading is not a mechanical act of absorbing facts. It is a slow, immersive process where the mind wrestles with ideas, pauses at confusion, rereads difficult passages, and forms personal interpretations.**

The authors of books and blogs have spent a significant amount of time in communicating their thoughts and ideas. They carry context that spans across several pages, nuances that unfold gradually, and the unique writing style of the author. This process matters because <u>learning happens during friction</u>. The moment you struggle to understand a paragraph is the moment your brain is actively working. That effort creates a durable understanding.

However, there's a growing cost that we rarely discuss.

When LLMs replace reading books and blogs, they quietly take away something essential: the joy of discovery, the struggle of understanding, and the depth that comes only from engaging directly with ideas.

This essay is not an argument against LLMs. It is an argument against using them in the wrong place.

When we skip directly to a summary, we skip the very process that makes knowledge stick. We're raising a generation that's **a mile wide, but only an inch deep**. The effects of this dangerous adaptation can be seen on our memories and cognitive capabilities . How many book summaries you've did in the past  vs how many you can actively recall? What important takeaways have stayed with you from those generated summaries of books and blogs? 

**LLMs are extraordinary tools for thinking with. Used as substitutes for reading, they quietly train us to stop thinking at all.** 

LLMs are exceptional at compression, but compression is also their biggest flaw when used for reading. They remove the novel arguments that reveal how an author thinks, the subtle contradictions and unresolved questions, and the emotional rhythm of a narrative or essay. What remains is a polished, structured, confident explanation that feels complete even when it isn't. This creates an illusion of understanding. We feel informed, but we haven't actually done the thinking ourselves. Over time, this trains us to consume ideas passively rather than engage with them critically.

I began noticing the hidden cost when I turned LLMs into my default reading mechanism. My retention dropped. My opinions weakened. Original thoughts became rarer. I wasn't understanding the ideas. I was recognizing them. I wasn't forming insights. I was repeating them. Knowledge slowly shifted from something I built to something I merely accessed.

This pattern extends beyond LLMs. We now doomscroll Instagram and X for "knowledge", mistaking constant exposure for learning. We skim endlessly but rarely sit with an idea long enough to let it change us. This erosion of attention is not accidental; it is the natural outcome of optimizing for speed over depth. **Real learning demands presence, and presence is exactly what our tools are training us to abandon.**

But now I'm taking a more deliberate approach: I'm not outsourcing the cognitive friction that happens when I read. As they say, *"Struggle is the way forward."*

Am I saying "Don't use LLMs"? Not at all. Just be deliberate.

If you use them correctly, LLMs are incredibly powerful. There's a famous quote on the internet: "You won't be replaced by AI. You'll be replaced by someone who uses AI."

So how should one use them? Use LLMs to get the background context jargons of a topic before actually reading the main topic. Use it to create a mind map. When you are done reading the main piece, use LLM to clarify any confusion you may have, challenge, and cross-check your interpretations. Another useful way to use an LLM is alongside reading. You can use it ask questions, explore counterarguments, and connect ideas across concepts found in books and blogs. This was the basis of 'building a second brain'.

If you use LLMs this way, you will amplify learning instead of erasing it. Now, compare this approach to just getting the summary of a topic in bullet points. So terse and boring!!

A simple, easy-to-apply mental model is: Read first.  Think second. Ask the LLM last.

With this approach, you will be in the driver's seat, and the LLM will be your co-pilot. This is what we had envisioned in the early days, where AI would make us powerful.

Books and blogs are not just containers of information. They are experiences that shape how we think, reason, and reflect. LLMs can accelerate learning, but they should not replace the slow, deeply human act of reading.  When we outsource reading entirely, we don't just lose depth, but we also lose the patience, curiosity, and effort that make understanding possible. With no real insights, we are slowly and unknowingly outsourcing our thinking to machines.
